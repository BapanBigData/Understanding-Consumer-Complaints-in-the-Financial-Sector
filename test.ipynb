{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import Param, Params, TypeConverters, HasOutputCols, \\\n",
    "    HasInputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark Version: 3.5.2\n",
      "Spark Session created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Print PySpark version to check if it's correctly installed\n",
    "print(\"PySpark Version:\", pyspark.__version__)\n",
    "\n",
    "# Create a Spark session to test Spark functionality\n",
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "\n",
    "# Check if the Spark session was created successfully\n",
    "print(\"Spark Session created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-1G0D7HE:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x24cfc05d210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|    Alice| 29|\n",
      "|      Bob| 31|\n",
      "|Catherine| 35|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Alice\", 29), (\"Bob\", 31), (\"Catherine\", 35)]\n",
    "df = spark.createDataFrame(data, [\"name\", \"age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------------+--------------------+--------------------+----------------------------+-----------------------+--------------------+-----+--------+----+--------------------------+-------------+--------------------+----------------------------+----------------+------------------+------------+\n",
      "|Date received|             Product|     Sub-product|               Issue|           Sub-issue|Consumer complaint narrative|Company public response|             Company|State|ZIP code|Tags|Consumer consent provided?|Submitted via|Date sent to company|Company response to consumer|Timely response?|Consumer disputed?|Complaint ID|\n",
      "+-------------+--------------------+----------------+--------------------+--------------------+----------------------------+-----------------------+--------------------+-----+--------+----+--------------------------+-------------+--------------------+----------------------------+----------------+------------------+------------+\n",
      "|     08/30/24|Credit reporting ...|Credit reporting|Improper use of y...|Reporting company...|                        NULL|                   None|Experian Informat...|   GA|   30213|None|                      None|          Web|            08/30/24|                 In progress|             Yes|               N/A|     9969390|\n",
      "|     09/06/24|Credit reporting ...|Credit reporting|Incorrect informa...|Public record inf...|                        NULL|                   None|TRANSUNION INTERM...|   VA|   23059|None|                      None|          Web|            09/06/24|                 In progress|             Yes|               N/A|    10025998|\n",
      "|     07/17/24|Credit reporting ...|Credit reporting|Improper use of y...|Reporting company...|                        NULL|   Company has respo...|TRANSUNION INTERM...|   PA|   15401|None|      Consent not provided|          Web|            07/17/24|        Closed with non-m...|             Yes|               N/A|     9543936|\n",
      "|     08/22/24|Credit reporting ...|Credit reporting|Problem with a co...|Their investigati...|                        NULL|                   None|TRANSUNION INTERM...|   OK|   73013|None|                      None|          Web|            08/22/24|                 In progress|             Yes|               N/A|     9884146|\n",
      "|     08/22/24|Credit reporting ...|Credit reporting|Problem with a co...|Their investigati...|                        NULL|                   None|TRANSUNION INTERM...|   IL|   60068|None|                      None|          Web|            08/22/24|                 In progress|             Yes|               N/A|     9884149|\n",
      "|     07/17/24|Credit reporting ...|Credit reporting|Incorrect informa...|Information belon...|                        NULL|                   None|       EQUIFAX, INC.|   MA|   02062|None|      Consent not provided|          Web|            07/17/24|        Closed with non-m...|             Yes|               N/A|     9537938|\n",
      "|     08/22/24|Credit reporting ...|Credit reporting|Problem with a co...|Investigation too...|                        NULL|                   None|TRANSUNION INTERM...|   MD|   20603|None|                      None|          Web|            08/22/24|                 In progress|             Yes|               N/A|     9884165|\n",
      "|     08/22/24|Credit reporting ...|Credit reporting|Incorrect informa...|Information belon...|                        NULL|                   None|TRANSUNION INTERM...|   IN|   46176|None|                      None|          Web|            08/22/24|                 In progress|             Yes|               N/A|     9884199|\n",
      "|     08/22/24|Credit reporting ...|Credit reporting|Unable to get you...|Other problem get...|                        NULL|                   None|TRANSUNION INTERM...|   TN|   385XX|None|                      None|          Web|            08/22/24|                 In progress|             Yes|               N/A|     9884208|\n",
      "|     09/06/24|Credit reporting ...|Credit reporting|Problem with a co...|Their investigati...|                        NULL|                   None|       EQUIFAX, INC.|   IL|   601XX|None|                      None|          Web|            09/06/24|                 In progress|             Yes|               N/A|    10026192|\n",
      "+-------------+--------------------+----------------+--------------------+--------------------+----------------------------+-----------------------+--------------------+-----+--------+----+--------------------------+-------------+--------------------+----------------------------+----------------+------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to your CSV file\n",
    "csv_file_path = 'complaints-2024-09-17_17_59.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the first 20 records\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# MongoDB connection string\n",
    "conn_string = \"mongodb://root:example@localhost:27017/admin\"\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(conn_string)\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
